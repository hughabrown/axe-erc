# Human Rights Due Diligence Assessment Guide
## Axelera AI

## Table of Contents

1. [Quick Reference](#quick-reference)
2. [Why do we have this Guide?](#why-do-we-have-this-guide)
3. [Scope](#scope)
4. [Responsibilities / Who does what](#responsibilities--who-does-what)
5. [Prohibition for Controversial Weapons](#prohibition-for-controversial-weapons)
6. [Risk Factors and Categorization](#risk-factors-and-categorization)
7. [Risk Assessment: two-step approach](#risk-assessment-two-step-approach)

**Annexes:**
- [Annex 1 - Information Required from Sales Team for sharing with ERC](#annex-1--information-required-from-sales-team-for-sharing-with-erc)
- [Annex 2 - Screening Tasks for the ERC](#annex-2---screening-tasks-for-the-erc)
- [Annex 3 - Risk Factor Assessment by the ERC](#annex-3--risk-factor-assessment-by-the-erc)

## Quick Reference

- **When to use:** Any sales opportunity involving dual-use applications, e.g. military / defense applications, and/or customers active in the military/defense sector.

- **Who does what:**
  - Sales Team provides customer info, end-user details, application description, industry sector
  - ERC assesses all cases
  - Chair decides on Medium and Board on High-risk opportunities

- **Process:** Stage 1 Preliminary Screening (1-2 days) → Stage 2 Enhanced DD (max 2 weeks) → ERC assessment

- **Key outcomes:**
  - Low-risk (GREEN): ERC decides a sales opportunity can proceed
  - Medium-risk (ORANGE): ERC recommends; Board Chair confirms
  - High-risk (RED): ERC recommends; Full Board votes

- **Timeline:** estimated 2 weeks (except if Board approval is required)

## Why do we have this Guide?

This Human Rights Due Diligence Guide ('Guide') is an operational and practical guide implementing Axelera AI's ESG and Responsible Use Policy for assessing dual-use sales opportunities in order to prevent potential human rights violations.

## Scope

This Guide is applicable prior to entering into any new sales opportunity potentially involving:

i. dual-use applications, e.g. any military / defense applications, and/or
ii. customers active in the military/defense sector.

## Responsibilities / Who does what

### Sales Team:

- Identifies triggering factors requiring assessment under this Guide, by completing checklist for each sales opportunity
- Provides customer and application information to the ERC for assessment
- Ensures third party sales (distributor and VAR) contracts impose compliance with the ESG and Responsible Use policy
- Implements enhanced conditions in sales contracts if so decided by the Board

The Sales Team awaits assessment by the ERC and relevant approval by the Board prior entering into a sales contract with a customer.

### Ethics Review Committee (ERC):

- Assesses all dual-use sales opportunities
- Provides recommendations to the Board on risk classification
- Monitors compliance with enhanced conditions applicable to sales opportunities

The ERC is composed of 3 members, appointed by the CEO. All members are employees and independent from the Sales department. The composition is as follows: Head of Legal, Director AI Integrated Systems and the Chief of Staff. The ERC can decide to be supported by an external advisor with expertise in business and human rights in the technology sector.

For each case, the ERC prepares an assessment report containing risk classification with rationale, due diligence findings and recommended conditions.

### Board:

- Oversees compliance with the ESG and Responsible Use Policy and this Guide
- Decides on medium (Board Chair) and high-risk (Full Board) sales opportunities
- No Board waiver possible for sales opportunities relating to controversial weapons (as defined here below)

## Prohibition for Controversial Weapons

Sales opportunities in relation to controversial weapons are prohibited, including:

- Nuclear, chemical and biological weapons
- Cluster munitions and anti-personnel mines
- Autonomous weapon systems (EU definition: weapon systems without meaningful human control over the critical functions of selecting and attacking individual targets).

## Risk Factors and Categorization

The following risk factors will be used as part of the assessment done by the ERC:

- End-use application and weaponization potential
- Customer profile and business activities
- Geographic deployment context

Risks are categorized as:

- **Low-risk (green):** Applications with minimal human rights concerns.
- **Medium-risk (orange):** Applications requiring enhanced due diligence, being legitimate dual-use applications
- **High-risk (red):** Applications with significant human rights implications

**Note:** the following factor automatically triggers high-risk classification:

- Customers domiciled in or controlled from jurisdictions credibly accused by UN bodies, international courts, or recognized human rights organizations of serious and systematic violations of international humanitarian law, human rights law, or atrocity crimes

## Risk Assessment: two-step approach

The ERC will assess dual-use opportunities as per the following process:

### Preliminary Screening (estimated 1-2 business days)

- Quick screening against prohibited activities and high-risk classification
  - Prohibited activities: sales opportunity will be rejected
  - High-risk sales opportunity: for decision by the Board
  - Sanctions check: performed by trade compliance, as part of the Export Control and Sanctions policy
  - Other sales opportunities: enhanced due diligence will follow

### Enhanced Due Diligence (estimated 2 weeks)

- Due diligence will follow based on the following risk factors
  - End-use application and weaponization potential
  - Customer profile and business activities
  - Geographic deployment context
- Final risk classification: Low/Medium/High

### Monitoring requirements:

The ERC monitors on an annual basis the dual-use customers for its compliance with the ESG and Responsible Use policy.

## Annex 1 – Information Required from Sales Team for sharing with ERC

### Essential Information (always required):

- Customer legal entity name and headquarters location
- End-user name and deployment country (if different from buyer)
- General application category (e.g., communications, reconnaissance, logistics, training)
- Industry sector (defense contractor, government agency, system integrator)

### Additional Information (provide what's available):

- Customer's public ethics statements or human rights policies (check website)
- Basic technical use case (e.g., "image processing for drone navigation")
- Whether application is offensive, defensive, or support-oriented
- Any certifications mentioned (ISO, defense standards)
- Whether human operators control key decisions

**Note:** Should customers be hesitant to provide details, please provide what you can obtain through normal sales discussions. The ERC will conduct additional research.

## Annex 2 - Screening Tasks for the ERC

### Preliminary Screening (estimated 1-2 business days)

#### 1. Controversial Weapons Screen:

- Review application description for weapons-related keywords
- Check for involvement with controversial weapons as defined in the ESG and Responsible Use Policy:
  - Nuclear, chemical, and biological weapons
  - Cluster munitions and anti-personnel mines
  - Autonomous weapon systems (weapons without meaningful human control)
- Flag any direct weapons production or distribution

#### 2. High-Risk Jurisdiction Check:

- Verify customer and end-user locations against high risk countries
- Check for UN Human Rights Council investigations

### Enhanced Due Diligence (estimated 2 weeks)

Based on the information received from Sales Team, the ERC will perform due diligence based on the following risk factors (as described in Annex 3):

1. End-use application and weaponization potential
2. Customer profile and business activities
3. Geographic deployment context

### Risk Classification and Actions

- All GREEN → Low-risk: ERC confirming sales opportunity can proceed
- Any ORANGE → Medium-risk: ERC assessment with confirmation required from Board Chair
- Any RED → High-risk: ERC recommendation with Board decision required (potentially acceptable with strong safeguards)

In each case enhanced conditions may be imposed, e.g. adhering to UN Guiding Principles on Business and Human Rights, regular monitoring, etc.

## Annex 3 – Risk Factor Assessment by the ERC

### Risk Factor 1: Geographic deployment context

This assessment aims to determine whether the deployment jurisdiction has sufficient legal safeguards and governance structures to prevent misuse of AI technology for human rights violations.

The points below are indicative of the risk classification of countries:

#### Low Risk – Stable, rights-respecting countries:

- EU or NATO member countries
- Freedom House 'Free rating' (score >70)
- Press Freedom Index score >60
- No UN Human Rights Council investigations

#### Medium Risk – Partially free or declining safeguards:

- Freedom House 'Partly Free' or declining trends
- Press Freedom Index score 30-60
- UN Human Rights Council recommendations issued with improvement efforts
- Democracies with governance gaps or declining trends

#### High Risk – Authoritarian or high misuse potential:

- Freedom House "Not Free" rating (score <40)
- Press Freedom Index score <30
- Documented misuse of technology for political repression (per UN bodies, Freedom House, Amnesty International, or Human Rights Watch reports)
- Conflict affected or authoritarian states

**Note:** Countries meeting automatic high-risk criteria (sanctions, serious and systematic human rights violations) will already have been flagged in the preliminary screening.

#### Research Sources:

- EU/NATO membership
- Freedom House ratings and recent trends
- Press Freedom Index: Reporters Without Borders rankings
- UN Human Rights Council reports for the country
- ICC and ICJ case dockets
- State Department Human Rights Reports
- Sanctions check (performed by trade compliance status (comprehensive vs targeted)
- Data protection, AI governance and surveillance laws in jurisdiction

### Risk Factor 2: Customer Profile and Business Activities

This assessment aims to determine the customer's ethical track record, governance practices, and commitment to international standards.

#### Low Risk:

- Companies that have adopted UN Guiding Principles on Business and Human Rights or similar frameworks
- Strong corporate governance with published ethics policies
- Clean compliance record with no violations in past 5 years
- Transparent operations and public sustainability reporting
- Public commitment to international humanitarian law compliance

**Example:** EU or NATO based customers (defense, governments) with strong ESG compliance programs or other well established, global customers with publicly available sustainability reports, clear corporate governance, and a strong track record of compliance with international humanitarian law, including adoption of the UN Guiding Principles on Business and Human Rights and publication of regular audits of their supply chain and ethics programs.

#### Medium Risk:

- Customers with established (human rights) compliance programs
- Government entities with democratic oversight mechanism
- Organizations subject to regulatory oversight in EU/NATO member states
- Companies with resolved violations (>3 years ago) and corrected actions taken

**Example:** Customers supplying to EU/NATO-aligned militaries. Having limited / less transparent compliance standards.

#### High Risk:

- Organizations with unresolved compliance violations and/or recent human rights concerns (within past 3 years)
- Entities with opaque ownership structure, limited transparency or unclear governance
- Companies in sensitive sectors without established ethics frameworks
- Organizations under active investigation by regulatory bodies (but not sanctioned)

**Example:** A privately owned drone manufacturer with limited human rights oversight. The company has opaque ownership, no published ethics policies, and was recently cited in investigative reports for supplying technology used in surveillance of political dissidents.

**Note:** Sanctioned entities and documented human rights violators are already rejected during the preliminary screening.

#### Research Source:

- Customer website for ethics/human rights policies and UNGP commitments
- Corporate registries and annual reports for governance structures
- Sanctions databases (UN, EU, US OFAC)
- Adverse media for ethics violations or human rights concerns
- Defense industry associations for human rights compliance standards

### Risk Factor 3: End-use application and weaponization potential

This factor assesses the impact in case the application would be misused or diverted to a bad actor. This factor considers three dimensions that directly drive misuse potential – and are important in assessing whether an application is low, medium or high risk:

1. Level of human control
2. Proximity to harm
3. Ease of repurposing for harm

#### Low Risk – Limited Misuse Potential

- Administrative, training, or logistical systems with minimal military impact
- Maintenance, diagnostics, or health/safety applications
- Defensive surveillance or access control that cannot directly enable attacks
- Misuse would result in operational inconvenience, not lethal effects

#### Medium Risk – Combat-Enabling Potential

- Reconnaissance, intelligence, or battlefield awareness tools
- Target identification or tracking that still requires human decision-making
- Defensive electronic warfare or countermeasure systems
- Misuse could facilitate or accelerate combat operations

#### High Risk – Near-Weaponization Potential

- Semi-autonomous strike or targeting systems
- AI modules that could be adapted to launch attacks with limited human oversight
- Technologies that, in the wrong hands, could directly enable lethal or indiscriminate use
- Close to prohibited autonomous weapon functionality

#### Research Source:

- Customer-provided technical documentation describing system functions and operator involvement
- Marketing or public materials for indications of autonomy or targeting capabilities
- Defense or security media reporting on the system's role in operations
- Internal technical review to assess whether the system could be repurposed for harmful use